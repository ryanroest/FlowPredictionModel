{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3074,
     "status": "ok",
     "timestamp": 1601207344591,
     "user": {
      "displayName": "Inge Groffen",
      "photoUrl": "",
      "userId": "12494588141047137946"
     },
     "user_tz": -120
    },
    "id": "seArV_9uYKJQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, RepeatVector, TimeDistributed\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 3061,
     "status": "error",
     "timestamp": 1601207344595,
     "user": {
      "displayName": "Inge Groffen",
      "photoUrl": "",
      "userId": "12494588141047137946"
     },
     "user_tz": -120
    },
    "id": "eFPojSEwYKJW",
    "outputId": "e91228a6-e83e-449e-b7e6-a91d83e84e52"
   },
   "outputs": [],
   "source": [
    "# load files from pre-processing\n",
    "\n",
    "X = np.load('X.npy') #rainpredictions, hour of day, month of year, holiday, ones\n",
    "y = np.load('y.npy')\n",
    "TimeHour = pd.read_csv('TimeHour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_gru' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-550d1bdbb8ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_hours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m24\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_gru\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_gru\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train_gru_shaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_gru\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_gru_shaped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_gru' is not defined"
     ]
    }
   ],
   "source": [
    "n_hours = 24\n",
    "n_features = X_train_gru.shape[1]\n",
    "days = int(X_train_gru.shape[0]/24)\n",
    "X_train_gru_shaped = np.reshape(X_train_gru, (days, n_hours, n_features))\n",
    "print(X_train_gru_shaped.shape)\n",
    "#X_train_gru, X_test_gru, Y_train_gru, Y_test_gru = train_test_split\n",
    "\n",
    "X_train_gru_shaped = ReshapeData(X_train_gru)\n",
    "Y_hours = 24\n",
    "Y_features = 1\n",
    "Y_days = int(Y_train_gru.shape[0]/24)\n",
    "Y_train_gru_shaped = np.reshape(Y_train_gru, (Y_days, Y_hours, Y_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WcaX5fkkYKJc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13612, 39)\n",
      "(10800,)\n",
      "[504.06447306 502.99539014 501.56176333 267.72203709 164.6846228\n",
      " 415.60606761 506.92554056 498.48488889 539.77078944 569.86896236\n",
      " 573.43357472 554.18056333 519.03118042 518.49464347 518.47689861\n",
      " 511.91231167 508.04069681 506.03197208 505.73850639 505.39583111\n",
      " 505.85508306 350.65611313 219.0446198  248.08282937]\n",
      "[[504.06447306]\n",
      " [502.99539014]\n",
      " [501.56176333]\n",
      " [267.72203709]\n",
      " [164.6846228 ]\n",
      " [415.60606761]\n",
      " [506.92554056]\n",
      " [498.48488889]\n",
      " [539.77078944]\n",
      " [569.86896236]\n",
      " [573.43357472]\n",
      " [554.18056333]\n",
      " [519.03118042]\n",
      " [518.49464347]\n",
      " [518.47689861]\n",
      " [511.91231167]\n",
      " [508.04069681]\n",
      " [506.03197208]\n",
      " [505.73850639]\n",
      " [505.39583111]\n",
      " [505.85508306]\n",
      " [350.65611313]\n",
      " [219.0446198 ]\n",
      " [248.08282937]]\n",
      "72.29804405333333\n"
     ]
    }
   ],
   "source": [
    "# split dataset in test and train\n",
    "\n",
    "def ReshapeXData(dataframe):\n",
    "    n_hours = 24\n",
    "    n_features = dataframe.shape[1]\n",
    "    days = int(dataframe.shape[0]/24)\n",
    "    dataframe_shaped = np.reshape(dataframe,(days, n_hours, n_features))\n",
    "    return dataframe_shaped\n",
    "\n",
    "def ReshapeYData(dataframe):\n",
    "    n_hours = 24\n",
    "    n_features = 1\n",
    "    days = int(dataframe.shape[0]/24)\n",
    "    dataframe_shaped = np.reshape(dataframe,(days, n_hours, n_features))\n",
    "    return dataframe_shaped\n",
    "\n",
    "print(X.shape)\n",
    "X_train_gru = X[0:10800,:]\n",
    "X_test_gru = X[10801:13609,:]\n",
    "Y_train_gru = y[0:10800]\n",
    "Y_test_gru = y[10801:13609]\n",
    "\n",
    "print(Y_train_gru.shape)\n",
    "X_train_gru_shaped=ReshapeXData(X_train_gru)\n",
    "X_test_gru_shaped = ReshapeXData(X_test_gru)\n",
    "Y_train_gru_shaped = ReshapeYData(Y_train_gru)\n",
    "Y_test_gru_shaped = ReshapeYData(Y_test_gru)\n",
    "print(Y_train_gru[0:24])\n",
    "print(Y_train_gru_shaped[0])\n",
    "print(Y_test_gru[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4v_avnjtYKJh",
    "outputId": "c2361f97-e309-4c5c-c861-702054d00873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 360 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      " - 2s - loss: 128.9268 - val_loss: 142.2633\n",
      "Epoch 2/150\n",
      " - 1s - loss: 122.8788 - val_loss: 96.8789\n",
      "Epoch 3/150\n",
      " - 1s - loss: 112.5196 - val_loss: 133.1177\n",
      "Epoch 4/150\n",
      " - 1s - loss: 118.2456 - val_loss: 121.6884\n",
      "Epoch 5/150\n",
      " - 1s - loss: 100.6797 - val_loss: 97.4614\n",
      "Epoch 6/150\n",
      " - 1s - loss: 91.0327 - val_loss: 93.8912\n",
      "Epoch 7/150\n",
      " - 1s - loss: 87.0796 - val_loss: 90.6273\n",
      "Epoch 8/150\n",
      " - 1s - loss: 82.9923 - val_loss: 85.0801\n",
      "Epoch 9/150\n",
      " - 1s - loss: 80.4087 - val_loss: 83.3145\n",
      "Epoch 10/150\n",
      " - 1s - loss: 78.6144 - val_loss: 85.1242\n",
      "Epoch 11/150\n",
      " - 1s - loss: 79.0350 - val_loss: 80.7843\n",
      "Epoch 12/150\n",
      " - 1s - loss: 76.9639 - val_loss: 79.8620\n",
      "Epoch 13/150\n",
      " - 1s - loss: 76.1364 - val_loss: 78.3073\n",
      "Epoch 14/150\n",
      " - 1s - loss: 75.7481 - val_loss: 77.1131\n",
      "Epoch 15/150\n",
      " - 1s - loss: 75.5419 - val_loss: 75.4215\n",
      "Epoch 16/150\n",
      " - 1s - loss: 75.1408 - val_loss: 78.5485\n",
      "Epoch 17/150\n",
      " - 1s - loss: 77.0367 - val_loss: 77.7821\n",
      "Epoch 18/150\n",
      " - 1s - loss: 80.2541 - val_loss: 84.9016\n",
      "Epoch 19/150\n",
      " - 1s - loss: 75.6575 - val_loss: 77.1130\n",
      "Epoch 20/150\n",
      " - 1s - loss: 73.7743 - val_loss: 73.7434\n",
      "Epoch 21/150\n",
      " - 1s - loss: 74.0225 - val_loss: 75.8910\n",
      "Epoch 22/150\n",
      " - 1s - loss: 73.1655 - val_loss: 72.8822\n",
      "Epoch 23/150\n",
      " - 1s - loss: 73.3653 - val_loss: 83.0293\n",
      "Epoch 24/150\n",
      " - 1s - loss: 74.5716 - val_loss: 73.9046\n",
      "Epoch 25/150\n",
      " - 1s - loss: 71.6519 - val_loss: 76.2475\n",
      "Epoch 26/150\n",
      " - 1s - loss: 72.5423 - val_loss: 74.7676\n",
      "Epoch 27/150\n",
      " - 1s - loss: 72.3693 - val_loss: 74.3002\n",
      "Epoch 28/150\n",
      " - 1s - loss: 73.6075 - val_loss: 80.1118\n",
      "Epoch 29/150\n",
      " - 1s - loss: 73.0373 - val_loss: 76.0531\n",
      "Epoch 30/150\n",
      " - 1s - loss: 71.2940 - val_loss: 74.9776\n",
      "Epoch 31/150\n",
      " - 1s - loss: 71.8839 - val_loss: 73.8710\n",
      "Epoch 32/150\n",
      " - 1s - loss: 69.5137 - val_loss: 73.9556\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 33/150\n",
      " - 1s - loss: 70.8777 - val_loss: 73.6008\n",
      "Epoch 34/150\n",
      " - 1s - loss: 69.0570 - val_loss: 74.4199\n",
      "Epoch 35/150\n",
      " - 1s - loss: 69.4554 - val_loss: 75.9958\n",
      "Epoch 36/150\n",
      " - 1s - loss: 68.5106 - val_loss: 73.5621\n",
      "Epoch 37/150\n",
      " - 1s - loss: 69.0419 - val_loss: 73.6201\n",
      "Epoch 38/150\n",
      " - 1s - loss: 68.6817 - val_loss: 75.0255\n",
      "Epoch 39/150\n",
      " - 1s - loss: 68.3583 - val_loss: 73.3844\n",
      "Epoch 40/150\n",
      " - 1s - loss: 68.2505 - val_loss: 73.8234\n",
      "Epoch 41/150\n",
      " - 1s - loss: 68.1305 - val_loss: 74.1355\n",
      "Epoch 42/150\n",
      " - 1s - loss: 68.2285 - val_loss: 73.7956\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 43/150\n",
      " - 1s - loss: 67.9301 - val_loss: 73.9328\n",
      "Epoch 44/150\n",
      " - 1s - loss: 67.9341 - val_loss: 74.0177\n",
      "Epoch 45/150\n",
      " - 1s - loss: 67.9037 - val_loss: 73.9529\n",
      "Epoch 46/150\n",
      " - 1s - loss: 67.9004 - val_loss: 73.9105\n",
      "Epoch 47/150\n",
      " - 1s - loss: 67.9032 - val_loss: 73.9903\n",
      "Epoch 48/150\n",
      " - 1s - loss: 67.8798 - val_loss: 73.9608\n",
      "Epoch 49/150\n",
      " - 1s - loss: 67.8729 - val_loss: 73.9248\n",
      "Epoch 50/150\n",
      " - 1s - loss: 67.8714 - val_loss: 73.8705\n",
      "Epoch 51/150\n",
      " - 1s - loss: 67.9099 - val_loss: 73.7446\n",
      "Epoch 52/150\n",
      " - 1s - loss: 67.8950 - val_loss: 73.8925\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 53/150\n",
      " - 1s - loss: 67.8505 - val_loss: 73.9096\n",
      "Epoch 54/150\n",
      " - 1s - loss: 67.8463 - val_loss: 73.9208\n",
      "Epoch 55/150\n",
      " - 1s - loss: 67.8448 - val_loss: 73.9344\n",
      "Epoch 56/150\n",
      " - 1s - loss: 67.8419 - val_loss: 73.9577\n",
      "Epoch 57/150\n",
      " - 1s - loss: 67.8404 - val_loss: 73.9745\n",
      "Epoch 58/150\n",
      " - 1s - loss: 67.8387 - val_loss: 73.9818\n",
      "Epoch 59/150\n",
      " - 1s - loss: 67.8374 - val_loss: 73.9899\n",
      "Epoch 60/150\n",
      " - 1s - loss: 67.8366 - val_loss: 73.9940\n",
      "Epoch 61/150\n",
      " - 1s - loss: 67.8360 - val_loss: 73.9931\n",
      "Epoch 62/150\n",
      " - 1s - loss: 67.8355 - val_loss: 73.9882\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "Epoch 63/150\n",
      " - 1s - loss: 67.8346 - val_loss: 73.9886\n",
      "Epoch 64/150\n",
      " - 1s - loss: 67.8346 - val_loss: 73.9891\n",
      "Epoch 65/150\n",
      " - 1s - loss: 67.8345 - val_loss: 73.9889\n",
      "Epoch 66/150\n",
      " - 1s - loss: 67.8345 - val_loss: 73.9897\n",
      "Epoch 67/150\n",
      " - 1s - loss: 67.8343 - val_loss: 73.9899\n",
      "Epoch 68/150\n",
      " - 1s - loss: 67.8347 - val_loss: 73.9876\n",
      "Epoch 69/150\n",
      " - 1s - loss: 67.8343 - val_loss: 73.9874\n",
      "Epoch 70/150\n",
      " - 1s - loss: 67.8342 - val_loss: 73.9883\n",
      "Epoch 71/150\n",
      " - 1s - loss: 67.8341 - val_loss: 73.9891\n",
      "Epoch 72/150\n",
      " - 1s - loss: 67.8340 - val_loss: 73.9894\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "Epoch 73/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9895\n",
      "Epoch 74/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9895\n",
      "Epoch 75/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 76/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 77/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 78/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9895\n",
      "Epoch 79/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9895\n",
      "Epoch 80/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9895\n",
      "Epoch 81/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9895\n",
      "Epoch 82/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9895\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 83/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 84/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 85/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 86/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 87/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 88/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 89/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 90/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 91/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 92/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "Epoch 93/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 94/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 95/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 96/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 97/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 98/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 99/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 100/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 101/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 102/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "Epoch 103/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 104/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 105/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 106/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 107/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 108/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 109/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 110/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 111/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 112/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "Epoch 113/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 114/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 115/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 116/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 117/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 118/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 119/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 120/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 121/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 122/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "Epoch 123/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 125/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 126/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 127/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 128/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 129/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 130/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 131/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 132/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "Epoch 133/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 134/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 135/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 136/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 137/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 138/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 139/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 140/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 141/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 142/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "Epoch 143/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 144/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 145/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 146/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 147/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 148/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 149/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n",
      "Epoch 150/150\n",
      " - 1s - loss: 67.8339 - val_loss: 73.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x251df0acc48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic model\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "lr=0.03\n",
    "epochs=150\n",
    "batch_size=50\n",
    "validation_split=0.1\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "n_timesteps, n_features, n_outputs = X_train_gru_shaped.shape[1], X_train_gru_shaped.shape[2], Y_train_gru_shaped.shape[1]\n",
    "# reshape output into [samples, timesteps, features]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(RepeatVector(n_outputs))\n",
    "model.add(GRU(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "model.fit(\n",
    "        X_train_gru_shaped,\n",
    "        Y_train_gru_shaped,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=2,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[\n",
    "            ReduceLROnPlateau(\n",
    "                verbose=1)])\n",
    "    \n",
    "    \n",
    "#model = Sequential()\n",
    "#model.add(Dense(1, input_dim=X.shape[1]))\n",
    "#model.compile(optimizer = optimizers.Adam(lr=lr), loss='mean_squared_error')\n",
    "#model.fit(X_train, y_train,\n",
    "#          validation_split=validation_split,\n",
    "#          epochs=epochs,\n",
    "#          batch_size=batch_size,\n",
    "#          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZBc7rFS6YKJm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 24, 1)\n",
      "(117, 24, 1)\n",
      "[106.69544]\n",
      "[109.39359994]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction to test how well the model preforms\n",
    "y_predicted = model.predict(X_test_gru_shaped)\n",
    "print(y_predicted.shape)\n",
    "print(Y_test_gru_shaped.shape)\n",
    "print(y_predicted[1][1])\n",
    "print(Y_test_gru_shaped[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d16htc7AYKJp"
   },
   "outputs": [],
   "source": [
    "### LZS: WE HAVE TO IMPLEMENT HERE SOME METRICS AND A LOT OF PLOTS SO THAT WE CAN SEE HOW WELL THE MODEL PERFORMS\n",
    "### LZS: AND ALSO TO BE ABLE TO FIND NEW FEATURES TO IMPROVE THE MODEL\n",
    "### LZS: AND TO EVALUATE IF THE MODEL INDEED IMPROVES WHEN ADDING MORE FEATURES/ OTHER LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EmRvBZZ9YKJs",
    "outputId": "d7d8e511-5762-4b38-8098-f58ceb5e845b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted=[43.815323], Original=[87.90307335]\n",
      "Predicted=[76.7759], Original=[119.33287184]\n",
      "Predicted=[87.58959], Original=[70.18270864]\n",
      "Predicted=[80.0803], Original=[82.55571344]\n",
      "Predicted=[73.42781], Original=[104.59264897]\n",
      "Predicted=[70.98996], Original=[72.29804405]\n",
      "Predicted=[70.889305], Original=[81.48252744]\n",
      "Predicted=[71.561195], Original=[0.02796992]\n",
      "Predicted=[72.308044], Original=[0.1253824]\n",
      "Predicted=[72.952934], Original=[0.3472128]\n",
      "Predicted=[73.513794], Original=[79.76302907]\n",
      "Predicted=[74.030365], Original=[80.90010568]\n",
      "Predicted=[74.523384], Original=[0.08824992]\n",
      "Predicted=[74.9992], Original=[85.22198364]\n",
      "Predicted=[75.458855], Original=[139.90204528]\n",
      "Predicted=[75.90261], Original=[94.68862363]\n",
      "Predicted=[76.33097], Original=[117.25686593]\n",
      "Predicted=[76.74473], Original=[90.74470117]\n",
      "Predicted=[77.1447], Original=[90.482204]\n",
      "Predicted=[77.53171], Original=[87.95206821]\n",
      "Predicted=[77.90649], Original=[0.09789472]\n",
      "Predicted=[78.26969], Original=[83.73856284]\n",
      "Predicted=[78.62194], Original=[90.25963047]\n",
      "Predicted=[78.96379], Original=[85.48163999]\n",
      "Predicted=[68.974205], Original=[158.31519683]\n",
      "Predicted=[106.69544], Original=[109.39359994]\n",
      "Predicted=[108.893135], Original=[82.29273939]\n",
      "Predicted=[99.065254], Original=[93.95610756]\n",
      "Predicted=[93.55779], Original=[83.82949924]\n",
      "Predicted=[91.82995], Original=[0.10175264]\n",
      "Predicted=[91.71108], Original=[81.95189086]\n",
      "Predicted=[92.06687], Original=[83.79846803]\n",
      "Predicted=[92.459], Original=[0.03906144]\n",
      "Predicted=[92.80421], Original=[0.09548352]\n",
      "Predicted=[93.116066], Original=[79.89201125]\n",
      "Predicted=[93.4132], Original=[0.00819808]\n",
      "Predicted=[93.70357], Original=[93.06856482]\n",
      "Predicted=[93.99012], Original=[87.56876462]\n",
      "Predicted=[94.27299], Original=[97.73007459]\n",
      "Predicted=[94.55154], Original=[89.06813788]\n",
      "Predicted=[94.825264], Original=[176.0452608]\n",
      "Predicted=[95.09414], Original=[84.56772435]\n",
      "Predicted=[95.358315], Original=[60.34823549]\n",
      "Predicted=[95.61787], Original=[120.21809135]\n",
      "Predicted=[95.87303], Original=[15.46886587]\n",
      "Predicted=[96.12391], Original=[123.07636948]\n",
      "Predicted=[96.37063], Original=[71.61046463]\n",
      "Predicted=[96.61334], Original=[143.77853102]\n",
      "Predicted=[47.001102], Original=[86.82127645]\n",
      "Predicted=[80.86645], Original=[85.58496551]\n",
      "Predicted=[90.49095], Original=[0.06847808]\n",
      "Predicted=[82.3603], Original=[28.52034272]\n",
      "Predicted=[75.763435], Original=[0.3472128]\n",
      "Predicted=[73.437195], Original=[0.3472128]\n",
      "Predicted=[73.36149], Original=[0.3472128]\n",
      "Predicted=[73.99578], Original=[0.3472128]\n",
      "Predicted=[74.69244], Original=[0.3472128]\n",
      "Predicted=[75.29277], Original=[0.3472128]\n",
      "Predicted=[75.81935], Original=[0.3472128]\n",
      "Predicted=[76.30845], Original=[0.3472128]\n",
      "Predicted=[76.77737], Original=[102.1889537]\n",
      "Predicted=[77.23118], Original=[459.65349918]\n",
      "Predicted=[77.67066], Original=[194.7375897]\n",
      "Predicted=[78.09603], Original=[124.95120772]\n",
      "Predicted=[78.50772], Original=[66.13101664]\n",
      "Predicted=[78.906364], Original=[0.22761728]\n",
      "Predicted=[79.29267], Original=[0.3472128]\n",
      "Predicted=[79.66732], Original=[242.28202185]\n",
      "Predicted=[80.03113], Original=[59.1633676]\n",
      "Predicted=[80.38491], Original=[0.3472128]\n",
      "Predicted=[80.729], Original=[0.3472128]\n",
      "Predicted=[81.06452], Original=[0.3472128]\n",
      "Predicted=[77.69131], Original=[0.3472128]\n",
      "Predicted=[116.283424], Original=[0.3472128]\n",
      "Predicted=[116.287674], Original=[0.3472128]\n",
      "Predicted=[106.504555], Original=[0.3472128]\n",
      "Predicted=[101.41343], Original=[0.3472128]\n",
      "Predicted=[99.80114], Original=[6.18291389]\n",
      "Predicted=[99.61611], Original=[455.9561809]\n",
      "Predicted=[99.86144], Original=[483.12345028]\n",
      "Predicted=[100.151436], Original=[489.82661889]\n",
      "Predicted=[100.41345], Original=[366.69489181]\n",
      "Predicted=[100.655495], Original=[85.24319247]\n",
      "Predicted=[100.888626], Original=[85.62876163]\n",
      "Predicted=[101.11715], Original=[81.32661337]\n",
      "Predicted=[101.34217], Original=[82.30637786]\n",
      "Predicted=[101.564], Original=[183.77992465]\n",
      "Predicted=[101.78279], Original=[87.35861411]\n",
      "Predicted=[101.99861], Original=[190.45968071]\n",
      "Predicted=[102.21151], Original=[96.92262633]\n",
      "Predicted=[102.42158], Original=[176.37836968]\n",
      "Predicted=[102.62888], Original=[83.62653002]\n",
      "Predicted=[102.83347], Original=[83.39533216]\n",
      "Predicted=[103.035446], Original=[135.05128274]\n",
      "Predicted=[103.23482], Original=[98.34540109]\n",
      "Predicted=[103.43171], Original=[112.33555339]\n",
      "Predicted=[47.193756], Original=[92.29195921]\n",
      "Predicted=[81.15363], Original=[83.00733527]\n",
      "Predicted=[90.75283], Original=[82.18785145]\n",
      "Predicted=[82.56977], Original=[81.35147567]\n",
      "Predicted=[75.95742], Original=[86.21829059]\n",
      "Predicted=[73.627426], Original=[79.36375629]\n",
      "Predicted=[73.54919], Original=[0.07812288]\n",
      "Predicted=[74.180954], Original=[78.10602944]\n",
      "Predicted=[74.8755], Original=[0.00144672]\n",
      "Predicted=[75.474144], Original=[0.25510496]\n",
      "Predicted=[75.99935], Original=[76.16326574]\n",
      "Predicted=[76.48719], Original=[0.03713248]\n",
      "Predicted=[76.95495], Original=[0.12393568]\n",
      "Predicted=[77.40768], Original=[85.71036233]\n",
      "Predicted=[77.84618], Original=[84.48354701]\n",
      "Predicted=[78.27064], Original=[85.53157415]\n",
      "Predicted=[78.6815], Original=[194.7572708]\n",
      "Predicted=[79.07938], Original=[153.561958]\n",
      "Predicted=[79.46499], Original=[111.78350055]\n",
      "Predicted=[79.83899], Original=[85.10996555]\n",
      "Predicted=[80.202324], Original=[105.58873942]\n",
      "Predicted=[80.55562], Original=[67.68180925]\n",
      "Predicted=[80.89927], Original=[81.9733259]\n",
      "Predicted=[81.23408], Original=[141.6010149]\n",
      "Predicted=[63.907463], Original=[117.67824081]\n",
      "Predicted=[101.13799], Original=[83.57188436]\n",
      "Predicted=[104.96726], Original=[82.80242527]\n",
      "Predicted=[95.14561], Original=[84.71785992]\n",
      "Predicted=[89.27064], Original=[83.35729475]\n",
      "Predicted=[87.40775], Original=[79.28867748]\n",
      "Predicted=[87.31654], Original=[0.06172672]\n",
      "Predicted=[87.74349], Original=[0.18903808]\n",
      "Predicted=[88.20327], Original=[76.63260117]\n",
      "Predicted=[88.60263], Original=[0.03038112]\n",
      "Predicted=[88.961174], Original=[0.20832768]\n",
      "Predicted=[89.30149], Original=[78.65072996]\n",
      "Predicted=[89.63268], Original=[86.56051104]\n",
      "Predicted=[89.95698], Original=[82.10159303]\n",
      "Predicted=[90.27465], Original=[95.76156312]\n",
      "Predicted=[90.58625], Original=[84.93847176]\n",
      "Predicted=[90.89301], Original=[144.70990179]\n",
      "Predicted=[91.19492], Original=[107.33382841]\n",
      "Predicted=[91.49146], Original=[86.71559889]\n",
      "Predicted=[91.782265], Original=[85.33423294]\n",
      "Predicted=[92.06735], Original=[12.40302644]\n",
      "Predicted=[92.34692], Original=[161.75175326]\n",
      "Predicted=[92.62116], Original=[26.43363895]\n",
      "Predicted=[92.890274], Original=[151.64836003]\n",
      "Predicted=[42.916794], Original=[85.09372469]\n",
      "Predicted=[75.57032], Original=[85.72181086]\n",
      "Predicted=[86.68772], Original=[174.22609917]\n",
      "Predicted=[79.38929], Original=[91.03703306]\n",
      "Predicted=[72.745186], Original=[31.98073909]\n",
      "Predicted=[70.28289], Original=[128.68128242]\n",
      "Predicted=[70.17577], Original=[1.25907609]\n",
      "Predicted=[70.85717], Original=[44.6158693]\n",
      "Predicted=[71.617256], Original=[32.41319776]\n",
      "Predicted=[72.27409], Original=[0.01543168]\n",
      "Predicted=[72.844185], Original=[0.15576352]\n",
      "Predicted=[73.36814], Original=[78.61457379]\n",
      "Predicted=[73.86758], Original=[89.06625598]\n",
      "Predicted=[74.3492], Original=[83.21433437]\n",
      "Predicted=[74.81414], Original=[83.36323852]\n",
      "Predicted=[75.26265], Original=[99.14578309]\n",
      "Predicted=[75.6953], Original=[76.84646586]\n",
      "Predicted=[76.11288], Original=[154.97695974]\n",
      "Predicted=[76.5163], Original=[14.45434477]\n",
      "Predicted=[76.90637], Original=[95.09274063]\n",
      "Predicted=[77.28388], Original=[69.05840828]\n",
      "Predicted=[77.64952], Original=[79.74148037]\n",
      "Predicted=[78.003944], Original=[86.03797659]\n",
      "Predicted=[78.3477], Original=[83.29562912]\n",
      "Predicted=[106.51969], Original=[113.53252404]\n",
      "Predicted=[143.02786], Original=[151.62087329]\n",
      "Predicted=[139.88571], Original=[84.05297]\n",
      "Predicted=[132.68349], Original=[87.49370796]\n",
      "Predicted=[129.22993], Original=[87.67010617]\n",
      "Predicted=[128.03087], Original=[80.58718329]\n",
      "Predicted=[127.73012], Original=[77.98551764]\n",
      "Predicted=[127.74099], Original=[75.84630967]\n",
      "Predicted=[127.81747], Original=[3.15221347]\n",
      "Predicted=[127.90095], Original=[0.04436608]\n",
      "Predicted=[127.98251], Original=[0.24787136]\n",
      "Predicted=[128.0623], Original=[76.95164296]\n",
      "Predicted=[128.14075], Original=[90.28122535]\n",
      "Predicted=[128.21832], Original=[87.26323799]\n",
      "Predicted=[128.29536], Original=[83.41035592]\n",
      "Predicted=[128.37201], Original=[84.11665172]\n",
      "Predicted=[128.4483], Original=[168.23015096]\n",
      "Predicted=[128.52426], Original=[46.91141039]\n",
      "Predicted=[128.59991], Original=[150.09752992]\n",
      "Predicted=[128.6752], Original=[260.14315422]\n",
      "Predicted=[128.75018], Original=[191.29094686]\n",
      "Predicted=[128.82483], Original=[106.82969636]\n",
      "Predicted=[128.89915], Original=[160.02241093]\n",
      "Predicted=[128.97314], Original=[86.58967926]\n",
      "Predicted=[55.182137], Original=[193.15685678]\n",
      "Predicted=[90.92489], Original=[133.58172877]\n",
      "Predicted=[97.643364], Original=[129.98198313]\n",
      "Predicted=[88.40035], Original=[99.35889126]\n",
      "Predicted=[82.09152], Original=[181.63131105]\n",
      "Predicted=[80.014885], Original=[84.26625545]\n",
      "Predicted=[79.956314], Original=[85.082005]\n",
      "Predicted=[80.497], Original=[86.14666851]\n",
      "Predicted=[81.07404], Original=[0.11477312]\n",
      "Predicted=[81.57119], Original=[77.41182709]\n",
      "Predicted=[82.01368], Original=[0.01109152]\n",
      "Predicted=[82.43075], Original=[90.17496112]\n",
      "Predicted=[82.83449], Original=[83.65583813]\n",
      "Predicted=[83.22767], Original=[83.80845202]\n",
      "Predicted=[83.61058], Original=[95.76157503]\n",
      "Predicted=[83.98336], Original=[84.06676653]\n",
      "Predicted=[84.34632], Original=[131.38129454]\n",
      "Predicted=[84.699875], Original=[83.6030057]\n",
      "Predicted=[85.04444], Original=[125.7375379]\n",
      "Predicted=[85.38061], Original=[90.94972797]\n",
      "Predicted=[85.71014], Original=[83.52436246]\n",
      "Predicted=[86.03334], Original=[84.26151918]\n",
      "Predicted=[86.349884], Original=[189.32682494]\n",
      "Predicted=[86.659294], Original=[491.97016833]\n",
      "Predicted=[71.407], Original=[492.51172958]\n",
      "Predicted=[109.402504], Original=[494.22584319]\n",
      "Predicted=[110.888374], Original=[344.68930636]\n",
      "Predicted=[101.05595], Original=[222.47583716]\n",
      "Predicted=[95.69421], Original=[185.97498281]\n",
      "Predicted=[94.012825], Original=[116.21960213]\n",
      "Predicted=[93.878555], Original=[227.17928206]\n",
      "Predicted=[94.20167], Original=[296.82919361]\n",
      "Predicted=[94.56256], Original=[206.18475096]\n",
      "Predicted=[94.88218], Original=[89.02801303]\n",
      "Predicted=[95.17266], Original=[80.90394092]\n",
      "Predicted=[95.45133], Original=[85.25921766]\n",
      "Predicted=[95.725105], Original=[146.35207069]\n",
      "Predicted=[95.99511], Original=[117.9072414]\n",
      "Predicted=[96.26085], Original=[84.01457792]\n",
      "Predicted=[96.522224], Original=[133.73981168]\n",
      "Predicted=[96.77926], Original=[74.06201219]\n",
      "Predicted=[97.03204], Original=[140.7202241]\n",
      "Predicted=[97.28069], Original=[81.7496744]\n",
      "Predicted=[97.52537], Original=[73.49416153]\n",
      "Predicted=[97.76615], Original=[99.84081552]\n",
      "Predicted=[98.00318], Original=[0.07185376]\n",
      "Predicted=[98.236565], Original=[83.09285022]\n",
      "Predicted=[98.46639], Original=[175.17786269]\n",
      "Predicted=[42.62069], Original=[86.89961999]\n",
      "Predicted=[75.18304], Original=[89.11734144]\n",
      "Predicted=[86.41212], Original=[84.42874191]\n",
      "Predicted=[79.17987], Original=[113.58108741]\n",
      "Predicted=[72.53304], Original=[62.55973431]\n",
      "Predicted=[70.059555], Original=[80.4669148]\n",
      "Predicted=[69.94915], Original=[0.08294528]\n",
      "Predicted=[70.63358], Original=[77.85194933]\n",
      "Predicted=[71.398224], Original=[78.0228563]\n",
      "Predicted=[72.059235], Original=[0.0265232]\n",
      "Predicted=[72.632484], Original=[0.03520352]\n",
      "Predicted=[73.15893], Original=[77.97084658]\n",
      "Predicted=[73.66049], Original=[0.024112]\n",
      "Predicted=[74.144035], Original=[84.59557594]\n",
      "Predicted=[74.61073], Original=[102.89532731]\n",
      "Predicted=[75.060814], Original=[162.4723886]\n",
      "Predicted=[75.494865], Original=[86.42295736]\n",
      "Predicted=[75.91371], Original=[185.9770098]\n",
      "Predicted=[76.31823], Original=[85.77477229]\n",
      "Predicted=[76.70931], Original=[84.0687238]\n",
      "Predicted=[77.08771], Original=[91.89146698]\n",
      "Predicted=[77.45414], Original=[83.15895694]\n",
      "Predicted=[77.80924], Original=[84.27194022]\n",
      "Predicted=[78.15361], Original=[83.03986543]\n",
      "Predicted=[43.146606], Original=[171.69920727]\n",
      "Predicted=[75.88248], Original=[94.90137189]\n",
      "Predicted=[86.92582], Original=[82.56092285]\n",
      "Predicted=[79.57134], Original=[53.36995288]\n",
      "Predicted=[72.92327], Original=[28.12943155]\n",
      "Predicted=[70.466515], Original=[79.28833843]\n",
      "Predicted=[70.36087], Original=[82.23959764]\n",
      "Predicted=[71.03985], Original=[0.08246304]\n",
      "Predicted=[71.79661], Original=[78.11708427]\n",
      "Predicted=[72.45044], Original=[0.036168]\n",
      "Predicted=[73.018196], Original=[0.21797248]\n",
      "Predicted=[73.5403], Original=[0.3472128]\n",
      "Predicted=[74.03811], Original=[76.76917634]\n",
      "Predicted=[74.51827], Original=[0.01591392]\n",
      "Predicted=[74.98189], Original=[177.74707873]\n",
      "Predicted=[75.42921], Original=[90.09644012]\n",
      "Predicted=[75.86077], Original=[178.3501075]\n",
      "Predicted=[76.27738], Original=[98.22069609]\n",
      "Predicted=[76.67995], Original=[168.38627527]\n",
      "Predicted=[77.06927], Original=[91.89025826]\n",
      "Predicted=[77.44609], Original=[81.46034074]\n",
      "Predicted=[77.81113], Original=[91.88691057]\n",
      "Predicted=[78.164986], Original=[82.08982989]\n",
      "Predicted=[78.50828], Original=[83.6939352]\n",
      "Predicted=[42.462273], Original=[83.62066386]\n",
      "Predicted=[74.96951], Original=[83.08966174]\n",
      "Predicted=[86.25256], Original=[95.53218791]\n",
      "Predicted=[79.05893], Original=[84.51086695]\n",
      "Predicted=[72.41405], Original=[80.30170828]\n",
      "Predicted=[69.93613], Original=[0.02796992]\n",
      "Predicted=[69.82436], Original=[78.29142798]\n",
      "Predicted=[70.51039], Original=[0.04870624]\n",
      "Predicted=[71.27737], Original=[0.05690432]\n",
      "Predicted=[71.94048], Original=[77.76085598]\n",
      "Predicted=[72.515366], Original=[0.01591392]\n",
      "Predicted=[73.0431], Original=[83.12918426]\n",
      "Predicted=[73.5458], Original=[81.8619527]\n",
      "Predicted=[74.03034], Original=[85.58328109]\n",
      "Predicted=[74.49793], Original=[94.22346178]\n",
      "Predicted=[74.948845], Original=[84.65036665]\n",
      "Predicted=[75.383644], Original=[120.92988613]\n",
      "Predicted=[75.80312], Original=[88.62973959]\n",
      "Predicted=[76.20823], Original=[145.52246718]\n",
      "Predicted=[76.599846], Original=[0.04050816]\n",
      "Predicted=[76.97869], Original=[80.12158381]\n",
      "Predicted=[77.34553], Original=[85.67426908]\n",
      "Predicted=[77.70098], Original=[82.28113305]\n",
      "Predicted=[78.04567], Original=[95.55256111]\n",
      "Predicted=[42.480995], Original=[126.5534311]\n",
      "Predicted=[74.99469], Original=[130.60734669]\n",
      "Predicted=[86.27131], Original=[92.52018623]\n",
      "Predicted=[79.07315], Original=[85.38667321]\n",
      "Predicted=[72.42806], Original=[82.36190615]\n",
      "Predicted=[69.95067], Original=[90.27945265]\n",
      "Predicted=[69.839096], Original=[78.96074522]\n",
      "Predicted=[70.52492], Original=[0.0072336]\n",
      "Predicted=[71.29162], Original=[0.05352864]\n",
      "Predicted=[71.95449], Original=[77.58163696]\n",
      "Predicted=[72.529175], Original=[0.04002592]\n",
      "Predicted=[73.05677], Original=[0.1374384]\n",
      "Predicted=[73.559326], Original=[167.71362929]\n",
      "Predicted=[74.04376], Original=[86.27080326]\n",
      "Predicted=[74.51125], Original=[83.10993225]\n",
      "Predicted=[74.96206], Original=[94.01729307]\n",
      "Predicted=[75.39674], Original=[82.44525197]\n",
      "Predicted=[75.81617], Original=[81.71870776]\n",
      "Predicted=[76.221214], Original=[89.58975565]\n",
      "Predicted=[76.612755], Original=[79.90535326]\n",
      "Predicted=[76.99155], Original=[0.0988592]\n",
      "Predicted=[77.358345], Original=[161.22780524]\n",
      "Predicted=[77.71375], Original=[4.27972594]\n",
      "Predicted=[78.058395], Original=[81.73353132]\n",
      "Predicted=[42.465958], Original=[182.36746017]\n",
      "Predicted=[74.97448], Original=[85.97811678]\n",
      "Predicted=[86.25628], Original=[84.02524352]\n",
      "Predicted=[79.061745], Original=[135.96599554]\n",
      "Predicted=[72.41682], Original=[47.997588]\n",
      "Predicted=[69.93899], Original=[81.37658766]\n",
      "Predicted=[69.82726], Original=[78.98322409]\n",
      "Predicted=[70.51324], Original=[0.02362976]\n",
      "Predicted=[71.28017], Original=[79.52787092]\n",
      "Predicted=[71.94324], Original=[0.14177856]\n",
      "Predicted=[72.51809], Original=[0.20880992]\n",
      "Predicted=[73.04581], Original=[78.55824556]\n",
      "Predicted=[73.548454], Original=[84.04016188]\n",
      "Predicted=[74.03299], Original=[92.20046763]\n",
      "Predicted=[74.500565], Original=[85.35606561]\n",
      "Predicted=[74.951454], Original=[86.76301638]\n",
      "Predicted=[75.38621], Original=[123.10339771]\n",
      "Predicted=[75.805695], Original=[44.18594743]\n",
      "Predicted=[76.21079], Original=[164.76726098]\n",
      "Predicted=[76.60238], Original=[2.1301366]\n",
      "Predicted=[76.98122], Original=[81.30752501]\n",
      "Predicted=[77.34805], Original=[90.58744751]\n",
      "Predicted=[77.70349], Original=[83.61733529]\n",
      "Predicted=[78.04817], Original=[83.83984276]\n",
      "Predicted=[46.84748], Original=[177.93349294]\n",
      "Predicted=[80.6675], Original=[96.84545007]\n",
      "Predicted=[90.35305], Original=[86.27281252]\n",
      "Predicted=[82.253716], Original=[91.68017618]\n",
      "Predicted=[75.656235], Original=[83.69848248]\n",
      "Predicted=[73.32536], Original=[82.21773135]\n",
      "Predicted=[73.248474], Original=[32.20598449]\n",
      "Predicted=[73.88443], Original=[53.50945411]\n",
      "Predicted=[74.58344], Original=[77.75658666]\n",
      "Predicted=[75.18598], Original=[0.02989888]\n",
      "Predicted=[75.71435], Original=[0.0747472]\n",
      "Predicted=[76.20488], Original=[81.20549169]\n",
      "Predicted=[76.67509], Original=[0.07667616]\n",
      "Predicted=[77.13005], Original=[167.27345484]\n",
      "Predicted=[77.57062], Original=[101.05151518]\n",
      "Predicted=[77.99698], Original=[82.55067259]\n",
      "Predicted=[78.40956], Original=[86.93054704]\n",
      "Predicted=[78.80902], Original=[83.27343492]\n",
      "Predicted=[79.19607], Original=[100.13327785]\n",
      "Predicted=[79.57139], Original=[104.26566612]\n",
      "Predicted=[79.93559], Original=[155.10362606]\n",
      "Predicted=[80.28967], Original=[17.39544603]\n",
      "Predicted=[80.63412], Original=[74.62210929]\n",
      "Predicted=[80.96981], Original=[166.3773177]\n",
      "Predicted=[47.746864], Original=[100.62303139]\n",
      "Predicted=[81.80695], Original=[95.66449532]\n",
      "Predicted=[91.16333], Original=[84.9786928]\n",
      "Predicted=[82.90726], Original=[84.09324887]\n",
      "Predicted=[76.33106], Original=[93.98197512]\n",
      "Predicted=[74.02989], Original=[82.46143102]\n",
      "Predicted=[73.95786], Original=[79.61611052]\n",
      "Predicted=[74.58222], Original=[0.03954368]\n",
      "Predicted=[75.266975], Original=[82.19300361]\n",
      "Predicted=[75.85706], Original=[0.05159968]\n",
      "Predicted=[76.37582], Original=[0.25655168]\n",
      "Predicted=[76.85853], Original=[78.07159194]\n",
      "Predicted=[77.321785], Original=[94.08102749]\n",
      "Predicted=[77.77036], Original=[84.93391566]\n",
      "Predicted=[78.20502], Original=[83.89168216]\n",
      "Predicted=[78.62596], Original=[93.45719822]\n",
      "Predicted=[79.03383], Original=[85.16331376]\n",
      "Predicted=[79.42943], Original=[147.5125683]\n",
      "Predicted=[79.81332], Original=[67.91742856]\n",
      "Predicted=[80.186], Original=[37.06835373]\n",
      "Predicted=[80.547905], Original=[90.75562856]\n",
      "Predicted=[80.89953], Original=[82.32050521]\n",
      "Predicted=[81.24139], Original=[83.22251086]\n",
      "Predicted=[81.57513], Original=[97.32402721]\n",
      "Predicted=[77.37368], Original=[103.1487286]\n",
      "Predicted=[115.21861], Original=[151.44882058]\n",
      "Predicted=[115.19684], Original=[83.62046252]\n",
      "Predicted=[105.78126], Original=[88.13724207]\n",
      "Predicted=[100.88889], Original=[83.4697672]\n",
      "Predicted=[99.34423], Original=[80.03378543]\n",
      "Predicted=[99.17451], Original=[0.0217008]\n",
      "Predicted=[99.42039], Original=[86.59315526]\n",
      "Predicted=[99.709595], Original=[0.1109152]\n",
      "Predicted=[99.972176], Original=[77.91594785]\n",
      "Predicted=[100.21552], Original=[0.03086336]\n",
      "Predicted=[100.45018], Original=[0.11863104]\n",
      "Predicted=[100.68024], Original=[88.87283319]\n",
      "Predicted=[100.90674], Original=[83.36664401]\n",
      "Predicted=[101.13], Original=[85.55319072]\n",
      "Predicted=[101.35017], Original=[163.66498922]\n",
      "Predicted=[101.567345], Original=[117.30199955]\n",
      "Predicted=[101.781555], Original=[140.84825995]\n",
      "Predicted=[101.992905], Original=[124.88745408]\n",
      "Predicted=[102.20144], Original=[84.13027712]\n",
      "Predicted=[102.40725], Original=[94.51576815]\n",
      "Predicted=[102.610374], Original=[83.31808759]\n",
      "Predicted=[102.810905], Original=[83.82120581]\n",
      "Predicted=[103.0089], Original=[84.99902208]\n",
      "Predicted=[60.99918], Original=[181.55153207]\n",
      "Predicted=[97.71896], Original=[85.63977331]\n",
      "Predicted=[102.45114], Original=[82.44104962]\n",
      "Predicted=[92.7988], Original=[34.0896744]\n",
      "Predicted=[86.79957], Original=[47.00345054]\n",
      "Predicted=[84.881096], Original=[82.54472654]\n",
      "Predicted=[84.80886], Original=[80.25751991]\n",
      "Predicted=[85.2765], Original=[0.07764064]\n",
      "Predicted=[85.77512], Original=[77.63367151]\n",
      "Predicted=[86.20583], Original=[0.01977184]\n",
      "Predicted=[86.59146], Original=[0.0892144]\n",
      "Predicted=[86.95673], Original=[26.86630874]\n",
      "Predicted=[87.311714], Original=[51.26039447]\n",
      "Predicted=[87.65876], Original=[0.01012704]\n",
      "Predicted=[87.99808], Original=[87.99671136]\n",
      "Predicted=[88.329765], Original=[172.28746605]\n",
      "Predicted=[88.65402], Original=[88.93424713]\n",
      "Predicted=[88.97245], Original=[149.37775189]\n",
      "Predicted=[89.28555], Original=[131.06074979]\n",
      "Predicted=[89.59304], Original=[84.18151813]\n",
      "Predicted=[89.894356], Original=[84.63408174]\n",
      "Predicted=[90.18945], Original=[87.05677937]\n",
      "Predicted=[90.47849], Original=[85.69547239]\n",
      "Predicted=[90.76169], Original=[83.40169064]\n",
      "Predicted=[64.59541], Original=[85.72207182]\n",
      "Predicted=[101.834236], Original=[88.98365158]\n",
      "Predicted=[105.40331], Original=[172.46844975]\n",
      "Predicted=[95.61396], Original=[83.32783584]\n",
      "Predicted=[89.818535], Original=[82.08754003]\n",
      "Predicted=[87.98603], Original=[0.03568576]\n",
      "Predicted=[87.893654], Original=[81.13229357]\n",
      "Predicted=[88.310425], Original=[52.89711924]\n",
      "Predicted=[88.75993], Original=[25.19258811]\n",
      "Predicted=[89.15112], Original=[0.00096448]\n",
      "Predicted=[89.50274], Original=[0.24550838]\n",
      "Predicted=[89.83675], Original=[79.66416758]\n",
      "Predicted=[90.161934], Original=[0.08149856]\n",
      "Predicted=[90.48046], Original=[171.26525728]\n",
      "Predicted=[90.7926], Original=[85.18903476]\n",
      "Predicted=[91.099556], Original=[95.08473122]\n",
      "Predicted=[91.40188], Original=[85.96143029]\n",
      "Predicted=[91.69935], Original=[83.8642471]\n",
      "Predicted=[91.99134], Original=[90.2149496]\n",
      "Predicted=[92.27771], Original=[82.65638182]\n",
      "Predicted=[92.55857], Original=[81.50889875]\n",
      "Predicted=[92.83407], Original=[85.33914985]\n",
      "Predicted=[93.10444], Original=[82.67901598]\n",
      "Predicted=[93.369835], Original=[96.72660161]\n",
      "Predicted=[53.496513], Original=[168.33889585]\n",
      "Predicted=[89.00991], Original=[86.28687544]\n",
      "Predicted=[96.38673], Original=[93.46124633]\n",
      "Predicted=[87.26208], Original=[84.63003437]\n",
      "Predicted=[80.82517], Original=[83.43546275]\n",
      "Predicted=[78.67792], Original=[80.24106394]\n",
      "Predicted=[78.613976], Original=[81.77482903]\n",
      "Predicted=[79.17482], Original=[0.00048224]\n",
      "Predicted=[79.77649], Original=[78.58791935]\n",
      "Predicted=[80.294945], Original=[0.00289344]\n",
      "Predicted=[80.75526], Original=[0.1109152]\n",
      "Predicted=[81.188225], Original=[0.02362976]\n",
      "Predicted=[81.60674], Original=[80.41327668]\n",
      "Predicted=[82.01379], Original=[170.68197408]\n",
      "Predicted=[82.40968], Original=[89.44322083]\n",
      "Predicted=[82.7946], Original=[71.90830182]\n",
      "Predicted=[83.16892], Original=[100.78699891]\n",
      "Predicted=[83.53309], Original=[81.07712965]\n",
      "Predicted=[83.8876], Original=[72.30981785]\n",
      "Predicted=[84.23292], Original=[98.82903022]\n",
      "Predicted=[84.569855], Original=[1.46463738]\n",
      "Predicted=[84.89999], Original=[79.94958635]\n",
      "Predicted=[85.22348], Original=[86.61525409]\n",
      "Predicted=[85.53998], Original=[83.4514244]\n",
      "Predicted=[43.256405], Original=[104.25013755]\n",
      "Predicted=[76.035484], Original=[162.64471158]\n",
      "Predicted=[87.046104], Original=[83.65060313]\n",
      "Predicted=[79.662766], Original=[95.58099457]\n",
      "Predicted=[73.01037], Original=[83.42027698]\n",
      "Predicted=[70.55515], Original=[88.58704437]\n",
      "Predicted=[70.44996], Original=[78.95124435]\n",
      "Predicted=[71.12786], Original=[0.06847808]\n",
      "Predicted=[71.88312], Original=[0.24015552]\n",
      "Predicted=[72.53556], Original=[78.95809741]\n",
      "Predicted=[73.102234], Original=[0.01157376]\n",
      "Predicted=[73.62345], Original=[78.63934749]\n",
      "Predicted=[74.12049], Original=[83.58007278]\n",
      "Predicted=[74.59995], Original=[95.24712488]\n",
      "Predicted=[75.06295], Original=[86.08517132]\n",
      "Predicted=[75.50968], Original=[165.50584107]\n",
      "Predicted=[75.94074], Original=[92.56159423]\n",
      "Predicted=[76.35691], Original=[91.69756263]\n",
      "Predicted=[76.759056], Original=[82.72581366]\n",
      "Predicted=[77.148], Original=[91.32593052]\n",
      "Predicted=[77.52451], Original=[82.08521663]\n",
      "Predicted=[77.88926], Original=[0.02700544]\n",
      "Predicted=[78.242874], Original=[88.40027734]\n",
      "Predicted=[78.58594], Original=[143.11329178]\n",
      "Predicted=[42.537384], Original=[114.37277636]\n",
      "Predicted=[75.0707], Original=[86.19014445]\n",
      "Predicted=[86.32809], Original=[94.21768237]\n",
      "Predicted=[79.11616], Original=[86.17992145]\n",
      "Predicted=[72.470375], Original=[84.34757223]\n",
      "Predicted=[69.99458], Original=[91.63003838]\n",
      "Predicted=[69.883484], Original=[81.29836935]\n",
      "Predicted=[70.56875], Original=[0.03520352]\n",
      "Predicted=[71.33463], Original=[78.4589226]\n",
      "Predicted=[71.996735], Original=[0.00916256]\n",
      "Predicted=[72.57084], Original=[0.19820064]\n",
      "Predicted=[73.09797], Original=[88.38879746]\n",
      "Predicted=[73.60012], Original=[83.33413172]\n",
      "Predicted=[74.08419], Original=[84.64162132]\n",
      "Predicted=[74.55137], Original=[107.05911973]\n",
      "Predicted=[75.001884], Original=[157.12604323]\n",
      "Predicted=[75.43632], Original=[60.18094386]\n",
      "Predicted=[75.85551], Original=[116.53285462]\n",
      "Predicted=[76.26034], Original=[82.33990107]\n",
      "Predicted=[76.651695], Original=[0.0699248]\n",
      "Predicted=[77.03034], Original=[81.44876762]\n",
      "Predicted=[77.39698], Original=[86.92589641]\n",
      "Predicted=[77.752266], Original=[82.18992412]\n",
      "Predicted=[78.0968], Original=[84.82393306]\n",
      "Predicted=[44.160416], Original=[91.52545409]\n",
      "Predicted=[77.23797], Original=[85.72169236]\n",
      "Predicted=[87.9352], Original=[107.14281566]\n",
      "Predicted=[80.34606], Original=[164.12557939]\n",
      "Predicted=[73.690094], Original=[82.90975593]\n",
      "Predicted=[71.2611], Original=[0.13078349]\n",
      "Predicted=[71.16268], Original=[80.71216092]\n",
      "Predicted=[71.83086], Original=[81.27744223]\n",
      "Predicted=[72.57262], Original=[0.06558464]\n",
      "Predicted=[73.21291], Original=[0.13888512]\n",
      "Predicted=[73.7702], Original=[39.24134384]\n",
      "Predicted=[74.28391], Original=[39.25505586]\n",
      "Predicted=[74.774414], Original=[95.0564605]\n",
      "Predicted=[75.24796], Original=[84.55589104]\n",
      "Predicted=[75.705574], Original=[84.88883174]\n",
      "Predicted=[76.14744], Original=[85.23024483]\n",
      "Predicted=[76.57411], Original=[145.40577278]\n",
      "Predicted=[76.98636], Original=[44.1546197]\n",
      "Predicted=[77.38497], Original=[77.76863352]\n",
      "Predicted=[77.77076], Original=[206.43517266]\n",
      "Predicted=[78.14443], Original=[95.77334574]\n",
      "Predicted=[78.50666], Original=[94.81761864]\n",
      "Predicted=[78.85804], Original=[145.97343004]\n",
      "Predicted=[79.199104], Original=[36.60885767]\n"
     ]
    }
   ],
   "source": [
    "# show the inputs, predicted outputs and real outputs\n",
    "for i in range(len(X_test_gru_shaped[0])):\n",
    "        for j in range(len(X_test_gru_shaped[1])):\n",
    "            print(\"Predicted=%s, Original=%s\" % (y_predicted[i][j], Y_test_gru_shaped[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3yZTmxVYKJw"
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with a prediction for all datapoints for the csv\n",
    "\n",
    "y_predicted_all = model.predict(X)\n",
    "y_pred_all = pd.DataFrame(data=y_predicted_all)\n",
    "\n",
    "my_df = pd.DataFrame({'Time': TimeHour.loc[:,'TimeHour'].tolist(), 'pred_y': y_pred_all.loc[:,0].tolist()})\n",
    "my_df.to_csv('FirstPredictions.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LZS_run_code_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
